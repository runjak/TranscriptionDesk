\documentclass{article}
\usepackage[german]{babel}
\usepackage[utf8]{inputenc}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{float}
\usepackage{url}

\usepackage[
  style=alphabetic, % Loads the bibliography and the citation style
  % bibstyle=alphabetic, % load a bibliography style
  % citestyle=alphabetic, % load a citatio style
  natbib=true, % define natbib compatible cite commands
%%--- Backend --- --- ---
  backend=biber,   % (bibtex, biber)
  bibwarn=true,     %
  texencoding=auto, % auto-detect the input encoding
  bibencoding=auto, % (auto (equal to tex), <encoding>)
]{biblatex}
\addbibresource{references.bib}

\title{Projektbericht TranscriptionDesk}
\author{Robert Rößling, Jakob Runge, Oliver Schurig, Franz Teichmann}
%\date{März 2015}

\begin{document}
%TODO: Stets zwei-drei Sätze Kapiteleinleitung beachten, englische Fachbegriffe auf ein Minimum reduzieren und nicht mehrere Begriffe für eine Semantik nutzen
% z.B. Nutzer statt User, Projekt statt Praktikum
%TODO genaue Beschreibung des Projektes erfolgt erst nach der analyse und Einordnung

\maketitle

\subsection*{Abstract}
Das TranscriptionDesk Projekt umfasste Konzeption und Entwicklung einer webbasierten Plattform,
auf der sich unterschiedlich versierte Nutzer zwecks Mitarbeit an der Transkription
einer großen Datenbasis aus Scans mittelalterlicher Handschriften registrieren können.
Dies beinhaltet außerdem die Analyse der Scans in Bezug auf die Unterscheidung zwischen Originaltext und nachträglicher Annotation.
Alle Quelldateien mit Dokumentation, Installationsanleitung und diesem Projektbericht
stehen unter MIT Lizenz und sind digital veröffentlicht unter \url{https://github.com/runjak/TranscriptionDesk}.

\tableofcontents
\newpage

%omeka-login: für jeden Scan ist die Herkunft mit drin
%CCBI NDNC für die meisten
\section{Einleitung}
Das Projekt TranscriptionDesk wurde im Zuge des Moduls ,,Citizen Science'' an der Universität Leipzig im Sommerstemester 2015 durchgeführt.
Das Thema umfasste die Konzeption und Entwicklung einer Webplattform nach dem Paradigma der Citizen Science,
welche eine dynamische Transkription einer großen Datenbasis bestehend aus Scans mittelalterlicher Handschriften ermöglicht.
In dieser Arbeit sollen die Hintergründe sowie unsere Ideen und Gedankengänge auf dem Weg vom Thema zum konkreten Projektauftrag,
die von uns betrachteten (Teil-)Aufgaben sowie die Ergebnisse präsentiert 
und die Architektur der entstandenen Software beschrieben werden.
Dazu sollen zunächst die theoretischen Grundlagen erläutert werden,
um daraus im Anschluss unsere Projektdefinition abzuleiten und
die Überlegungen aus der Planungsphase zusammenzufassen.
Danach soll ein direkter Einstieg ins Projekt mit der Darstellung der Architektur und der Produktfunktionen erfolgen und auf Funktionen hingewiesen werden, welche bisher aufgrund des begrenzten Zeitrahmens nicht umgesetzt werden konnten.
Am Schluss des Berichtes wird eine Zusammenfassung der ,,lessons learned'' sowie ein Ausblick auf mögliche Folgeprojekte gegeben.

\section{Theoretische Grundlagen}
In diesem Kapitel sollen die Grundlagen für die späteren Erläuterungen gelegt werden.
Dazu soll zunächst die Definition von Citizen Science aus der Vorlesung rekapituliert und auf verschiedene Deutungen des Begriffes eingegangen werden, um anschließend eine Arbeitsdefinition als Plan für unser Projekt abzuleiten und diesen in die Kategorien der Citizen Science nach Crowston und Wiggins einzuordnen.
Es sei hierbei auch auf Literatur zum Thema verwiesen.

Es handelt sich bei ,,Citizen Science'' um einen verhältnismäßig neumodischen Begriff
für ein gleichnamiges Teilgebiet der angewandten Sozial- und Geisteswissenschaften,
was nicht bedeutet, dass die Idee hinter dem Begriff Citizen Science grundsätzlich neu ist.
Tatsächlich lassen sich Aktivitäten, die heutzutage unter diesem Begriff zusammengefasst werden,
fast 200 Jahre in der Geschichte zurückverfolgen.
Anwendungsmöglichkeiten und die Komplexität dieses Themengebietes
wurden uns im Laufe der Lehrveranstaltung an aktuellen sowie an historischen Beispielen veranschaulicht
und sowohl Gemeinsamkeiten als auch Unterschiede zwischen den verschiedenen in den Beispielen verfolgten Ansätzen herausgearbeitet.
Da es keine ,,einfache'' oder ,,schnelle'' Definition gibt, die diesen Sachverhalt vollständig beschreibt,
versuchen wir die Komplexität noch einmal in den zwei folgenden Unterkapiteln einzufangen
und einer Definition so nahe zu kommen, wie es uns möglich ist.

\subsection{Definition Citizen Science}
Der Frage nach der Definition von Citizen Science versucht Wiederhold\cite{Wiederhold} (S.703-4) in ihren Arbeiten mit der Annäherung über den Begriff des ,,Citizen Scientist'' zu beantworten.
Es werden dazu aktuelle Entwicklungen, wie etwa das relativ bekannte FoldIt-Spiel \footnote{
FoldIt ist ein Onlinespiel, das sich mit Eigenschaften von Proteinen befasst. Der Spieler benötigt keinerlei biologisches Hintergrundwissen, sondern ein Gefühl für räumliche Bewegung der Spielelemente. Spielergebnisse liefern wertvolle Daten für Wissenschaftler und haben zu wichtigen Erkenntnissen in der Virenforschung geführt. \url{https://fold.it/portal/}}, 
sowie historische Beispiele betrachtet, die in die Citizen Science eingeordnet werden.
Eines der ältesten bekannten Projekte, so Wiederhold, ist das National Audubon Society's Christmas Bird Count-Projekt\footnote{Das Projekt wurde 1900 von Frank M. Chapman gegründet.
Ziel war es, Vogelarten zu bestimmen und zu zählen, um der bis dahin üblichen ,,Side Hunt'',
die jedes Jahr zur Weihnachtszeit Jäger dazu herausforderte, so viele Vögel wie möglich zu schießen,
eine umweltverträgliche Alternative zu bieten. \url{https://www.audubon.org/conservation/science/christmas-bird-count}}.
Auch heute ist dieses Projekt noch relevant, wie die dazu existierende Homepage mit aktuellen Nachrichten verdeutlicht.\\
Diese zwei Beispiele lassen gleichzeitig auch eine Bereicherung der historischen Citizen Science durch die digitale Welt erkennen.
Obwohl viele bekannte Projekte weiterhin unter ,,Environmental Science'', wie Wiederhold sie nennt, einzuordnen sind,
besteht in einer großen Anzahl der Projekte die Arbeit für den Citizen Scientist nur aus nicht maschinell abstrahierbarer Computerarbeit,
welche wenig bis keine Vorkenntnisse erfordert.\\
Unter Berücksichtigung dieser Betrachtungen definiert Wiederhold den Citizen Scientist nach Cohn\cite{Cohn}: 
,,The term 'citizen scientists' refers to volunteers who participate as field assistants in scientific studies.
Citizen scientists...are not paid for their assistance, nor are they necessarily even scientists.''(58:192-7).
Diese Definition beschreibt treffend die Rahmenbedingungen, unter denen ein solcher Citizen Scientist arbeitet 
und in welche Themengebiete er sich einbringt, jedoch lässt sie entscheidende Aspekte für die Definition der Citizen Science selbst vermissen.\\
Fragen die nicht beantwortet werden, sind beispielsweise solche nach dem Rahmen bei der Bestimmung einer Forschungsfrage,
dem notwendigen Grad an Wissenschaftlichkeit des Projektes, oder auch welche Finanzierungsmöglichkeiten für derartige Projekte bestehen.
Der Idee der Definition über den Citizen Scientist folgend beschreibt Cohn Citizen Science als 
,,die wissenschaftlichen Aktivitäten in denen nicht-professionelle Wissenschaftler sich freiwillig an Datensammlung, 
Analyse und Verbreitung eines wissenschaftlichen Projekts beteiligen.''\cite{Cohn}.\\
Für ihn ist der Citizen Scientist eindeutig wissenschaftlich tätig und dieser Aspekt spielt eine entscheidende Rolle 
bei der Konzeption von Projekten. Unserer Meinung nach ist diese Definition treffend und für unser Projekt präzise genug, 
auch wenn die Frage nach den Finanzierungsmöglichkeiten vorerst unbeantwortet bleibt.\\
Auch wird in dieser Definition keine klare Grenze zum Crowdsourcing
\footnote{Crowdsourcing: Bezeichnend für das Auslagern interner Aufgaben eines Unternehmens an Freiwillige Nicht-Angestellte. 
Angelehnt an den Begriff Outsourcing, bei dem Drittunternehmen ausgelagerte Aufgaben verrichten. 
Häufig wird Crowdsourcing über das Internet realisiert.} gezogen.\\
Um diese Fragen für uns beantworten zu können, befassten wir uns mit unterschiedlichen, bereits existierenden Projekten.
Einige davon gehörten eindeutig zum Crowdsourcing, andere wiederum waren für uns nicht so eindeutig zuzuordnen.
Gewissermaßen kann man also Crowdsourcing und reine Citizen Science als zwei gegensätzliche Pole einer Skala betrachten.
Dieser Meinung ist auch Haklay\cite{Haklay} (pp 105-122), der eine solche Skala näher analysierte, 
worauf im kommenden Kapitel eingegangen werden soll.
Auch Crowston und Wiggins\cite{CW} leisteten bedeutende Arbeit für die praktische Einordnung von Projekten in die Citizen Science.
Laut ihren Untersuchungen lässt sich das Spektrum der Projekte in folgende fünf Kategorien unterteilen:
,,Based on the clustering, we identified five mutually exclusive and exhaustive types of projects,
which we labelled Action, Conservation, Investigation, Virtual and Education'' (S. 5).
Auch diese sollen im Folgekapitel noch einmal einzeln Erwähnung finden.


\subsection{Kategorien der Citizen Science}

Nach Hacklay existieren folgende vier Abstufungen\cite{Haklay} (pp 115) in der Charakterisierung von Projekten zwischen Citizen Science und Crowdsourcing.
\begin{enumerate}
\item{Level 1: Crowdsourcing\\
Hier hat die einfache Nutzerschaft lediglich die Aufgabe der Datenerhebung, die Interpretation erfolgt an anderer Stelle.}
\item{Level 2: Distributed Intelligence\\
Auf diesem Level sollen freiwillige Nutzer Denkarbeit verrichten und werden dabei grundlegend für interpretative Aufgaben eingesetzt.}
\item{Level 3: Participatory Science\\
In dieser Kategorie werden die Freiwilligen bereits in der Problemdefinition mit einbezogen, sie übernehmen aber auch Aufgaben zur Sammlung von Daten.}
\item{Level 4: Extreme Citizen Science\\
Diese Kategorie betrachtet den gesamten wissenschaftlichen Prozess als kollaborative Aufgabe für die freiwillige Nutzerschaft.
Sie nimmt an der Problemdefinition ebenso teil wie an der Sammlung von Daten und deren Analyse.}
\end{enumerate}
Während Haklay versucht, den Unterschied der Citizen Science nach außen abzugrenzen, gibt es wie im letzten Kapitel beschrieben auch 
Bestrebungen, die Citizen Science in aussagekräftige Kategorien zu teilen. Crowston und Wiggins definierten hierfür folgende fünf Cluster: 
\begin{itemize}
\item{Action\\
Bei Action handelt es sich um Projekte, die ihren Ursprung häufig in einem lokal begrenzten Umfeld haben.
Sie werden nicht durch Wissenschaftler in die Wege geleitet,
sondern ,,einfache'' Leute, die einen singulären Handlungsbedarf sehen und eine Bewegung für Freiwillige ins Leben rufen.
Für gewöhnlich geht es dabei um Ziele, welche die Umwelt betreffen.
Technologien kommen dabei nur minimal zum Einsatz, soweit sie von Notwendigkeit sind.}
\item{Conservation\\
Conservation befasst sich mit dem Management und Erhalt der natürlichen Ressourcen bzw. Biodiversität.
Freiwillige haben dabei häufig Verwaltungsaufgaben oder sind dafür zuständig, eine breitere Masse zu erreichen.
Folglich ist auch Wissensvermittlung ein untergeordnetes Ziel, dieser Art von Projekten.
Finanzierung ist oft ein Problem, das nur über staatliche Gelder gelöst werden kann und oft 
zu starker Abhängigkeit von entsprechenden Stellen führt.}
\item{Investigation\\
Investigation hat wissenschaftliche Datenerhebungen zum Ziel.
Hier werden Daten von Freiwilligen im physikalischen Umfeld gesammelt.
Bildung und Wissensvermittlung sind hier zwar kein explizites Ziel, oft jedoch sind Vorkenntnisse der freiwilligen Helfer ein Faktor,
der die Arbeit erheblich genauer und effizienter gestaltet.}
\item{Virtual\\
Virtual weist viele Parallelen zu Investigation auf, spielt sich jedoch in virtueller Umgebung ab.
Besonders hier ist es nicht so leicht, die Teilnehmer als Citizen Scientists wahrzunehmen, da sie oft nur eine Zwischeninstanz darstellen, 
welche Daten verarbeitet.
Probleme, mit denen man sich hier besonders befassen muss ist die Validierung der Daten und das Management 
einer große Masse an Nutzern, die auf teilweise sehr komplexen Plattformen agiert.}
\item{Education\\
Education hat, wie der Name vermuten lässt, einen primären Bildungsauftrag.
Nicht immer ist es dabei leicht, ausreichend Gelder über Sponsoren zu erhalten, da meist nur ein geringer wissenschaftlicher oder
wirtschaftlicher Mehrwert erzielt wird.}
\end{itemize}
Sicher lassen sich noch wesentlich mehr Kategorien für konkrete Anwendungsfälle finden,
doch für den Zweck der Charakterisierung und Einordnung unseres Projektes sollen die Arbeiten von Haklay sowie Crowston und Wiggins als 
Referenz genügen.

\subsection{Einordnung des TranscriptionDesk}
Unserer Einschätzung nach ist TranscriptionDesk aufgrund der Aufgabenstellung der interpretierenden Transkription auf Haklays Skala näher am
Crowdsourcing als an der extreme Citizen Science einzuordnen.
Das Level 2, also die ,,Distributed Intelligence'' erscheint uns passend, da die freiwilligen Mitarbeiter 
eine Analyse, also eine klare Denkleistung durchführen sollen.
Außerdem ist mit der Problemdefinition das Projektziel bereits vorgegeben, so dass die Vorraussetzungen für Level 3 nicht gegeben sind.\\
Schauen wir uns die Kategorien von Crowston und Wiggins an, so müssen wir TranscriptionDesk zwangsläufig zur Kategorie ,,Virtual'' zählen.
Alle Faktoren des Projektes treffen exakt zu.\\
Auch einige wenige Faktoren der Action-Kategorie werden ebenfalls erfüllt, da Beispielsweise der Ursprung des Projektes darin liegt,
dass Daten vorhanden sind, die transkribiert und validiert werden müssen und somit eine Notwendigkeit zum Handeln 
den Ausschlag für das Projekt gab.
Das Hauptargument gegen die Action-Kategorie ist, dass es keinen lokal begrenzten, umweltbezogenen Faktoren für den Handlungsbedarf gab.

\section{Projektübersicht}
In diesem Kapitel soll mit einer detaillierten Übersicht über das Projekt und dessen Zielstellung ein direkter Einstieg geben werden.
Dazu soll ausgehend von der Projektvision die Struktur der Datenbasis erläutert und die erwartete Nutzerbasis reflektiert werden.

\subsection{Ziele}
Unser Projektthema fand seine Motivation in der Abteilung der Digitalen Geistes-wissenschaften der Universität Leipzig.
Dort liegen tausende Scans mittelalter-licher Schriftstücke vor, deren Informationsgehalt ohne vorherige Transkription nicht digital zu verarbeiten ist.
Es wurde als unmöglich bewertet, den Inhalt der Schriftstücke mittels typischer Optical-Character-Recognition-Methoden (OCR) sinnvoll zu digitalisieren.
Das hat im Wesentlichen zwei Gründe.\\
Einerseits war Papier im Mittelalter Mangelware und somit ein wertvolles Gut, welches sparsam verwendet wurde.
Deswegen nutzte man freien Platz gut aus und es gibt Passagen,
die nicht in einen gemeinsamen zeitlichen Kontext gehören (z.B. nachträgliche Annotationen) und somit händisch getrennt werden müssen.
Der Fakt, dass die Schriftstücke aufgrund ihres Alters bereits durch viele Hände gegangen sind und im Laufe der Zeit
mit unterschiedlichen Handschriften auf dem Papier gearbeitet wurde, erschwert OCR umso mehr.
Diese Informationen sollen entsprechend getrennt und digitalisiert werden.\\
Der zweite Grund besteht darin, dass das Schriftbild des Mittelalters oft künst-lerisch aufgewertet wurde.
So waren Texte in Blockform sehr beliebt und man erfand allerlei unterschiedliche Formen für semantisch gleichbedeutende Buchstaben,
die durch ihre Vielfalt für einen OCR-Algorithmus praktisch unmöglich zu lesen sind.\\
Die Aufgabe, welche sich daraus ergibt, kann praktisch nur durch akribische, händische Arbeit gelöst werden.
An dieser Stelle soll die Citizen Science ins Spiel kommen; durch den Aufbau einer Webplattform könnte ein großer Teil der Arbeit nach außen,
an Freiwillige mit unterschiedlichen Erfahrungen und unterschiedlichem Wissen abgegeben werden.
Dadurch soll die Digitalisierung der auf den Scans enthaltenen Texte beschleunigt, wenn nicht erst ermöglicht werden.\\
Das Ziel, das wir vor Augen haben ist also der Aufbau einer Weboberfläche, welche die Scans einer offene Gruppe freiwilliger Nutzer anbietet,
ihnen die Werkzeuge für deren Bearbeitung bereitstellt, die Ergebnisse speichert, und der Nutzerschaft die Möglichkeit bietet,
ihre gegenseitigen Ergebnisse zu bewerten, um ein einheitliches Level an Validierung der digialisierten Texte anzustreben.
Die Seite soll so strukturiert sein, dass sie weitestgehend selbstverwaltend ist und lediglich einige wenige Administratoren
die verbleibenden Verwaltungsaufgaben erledigen können.
Dabei ist auch die Möglichkeit gegeben, diese Administratoren ebenfalls in Teilen aus der Nutzerbasis zu beziehen.\\
Die Arbeit für einen Nutzer soll aus zwei unterschiedlichen Aufgaben bestehen.
\begin{itemize}
\item{Erstere besteht darin, Rechtecke auf den Scans zu ziehen, um ,,Areas of Interest'' zu markieren.
Dies können beispielsweise Bilder oder zusammengehörende Textfetzen sein.
Das Ergebnis ist eine Interest Map eines Scans, die andere Nutzer bewerten können, um deren Akzeptanz wiederzuspiegeln.
Scans können direkt ausgewählt oder per Zufall zugeordnet werden.}
\item{Die zweite Aufgabe besteht aus der eigentlichen Transkription.
Eine Interest Map wird verwendet und die darauf enthaltenen Areas of Interest werden vom Nutzer mit einer Transkription versehen.
Auch dieses Ergebnis wird gespeichert und bewertet und es wird ein bestes Ergebnis ermittelbar.}
\end{itemize}
Unsere Aufgabe ist es dabei, all diese Funktionen als Grundfunktionalität zu implementieren und sie ansprechend zu gestalten.
Der letzte Punkt ist für uns sehr wesentlich, da bei unserer Recherche auffiel, dass ähnliche (und darunter technisch gesehen sehr gute)
Projekte bereits an kleinen Schönheitsfehlern scheitern mussten, weil die Nutzer sich einfach nicht angesprochen fühlten.
Zusätzlich gehört es aus mehreren Gründen zu unserem Ziel, eine Login-Routine für das User-Management aufzubauen.
Dies bietet viele Vorteile beim Verfolgen von Veränderungen, für eine faire Verteilung von Bewertungen,
oder etwa um Statistiken einzelner oder auch aller Nutzer zu erstellen.\\
Außerdem besteht eine unserer wichtigsten Aufgaben darin, auf der gesamten Weboberfläche Unicode verwendbar und lesbar zu machen.
Ganz speziell bedeutet das, das wir eine sehr umfangreiche Eingabemaske aufbauen müssen,
die einen mächtigen Satz an mittelalterlichen Sonderzeichen in einer nutzerfreundlichen Art und Weise hergibt.
Die Identifikation von Scans erfolgt über Cite URNs.% Quelle für Cite URNs zitieren! FIXME
Wir wollen die Areas of Interest durch Erweiterung des Konzeptes ebenfalls über jene Cite URN identifizieren können.\\
Die bisher genannten Features haben die höchste Priorität und bilden die Grundfunktionalität unserer Weboberfläche.
Ab diesem Punkt lassen sich schrittweise weitere Features hinzufügen um die Arbeit zu erleichtern, angenehmer oder einfach ansprechender zu gestalten.
Deswegen haben wir unsere anfängliche Planung mittels Scrum an ein agiles Entwicklungsmodell angelehnt.\\
Zuerst planten wir unsere grobe Architektur sowie diverse Technologien, die wir verwenden könnten.
Auf beides werden wir in Folgekapiteln noch einen genaueren Blick werfen. Dann wurden drei Meilensteine geplant,
wobei der erste davon für die Erstellung der Nutzerauthentifikationsroutine und die Anbindung der im Hintergrund genutzten Dienste enthielt.
Im zweiten Meilenstein ging es im Prinzip um alles, was die Maske der Weboberfläche sowie die Implementation der Arbeitswerkzeuge für die Nutzer betrifft.
Damit sollte die Grundfunktionalität weitestgehend aufgebaut sein. Für alle Eventualitäten soll es noch einen dritten Meilenstein geben,
in dem konkrete Bugs gelöst werden sollen und, falls dann noch ausreichend Zeit bleibt, direkt weitere Funktionen implementiert werden können.
\subsection{Struktur der Datenbasis}
Wie sehen unsere Dokumente und Rohdaten aus?
Wo kommen diese Daten her?
%Open Philology-Project letzten Jahres. Bei Omeka einloggen um Infos detailiert zu sehen. Falls dort nicht zu sehen, SOFORT THOMAS BESCHEIDGEBEN!

\subsection{Produkteinsatz / Erwartete Userbasis}
Ausgehend von der Motivation des Projektes sehen wir den vielversprechendsten Weg der Umsetzung logischerweise im Citizen Science Paradigma.
Es werden Freiwillige benötigt, die ein persönliches Interesse darin haben, an der Entwicklung und dem Erfolg des Projektes mitzuwirken.
Unsere Aufgabe ist es, nicht nur eine Plattform zur Verfügung zu stellen, auf der die entsprechende Arbeit verrichtet werden kann,
sondern auch für Nutzer einen Anreiz zur Aufnahme der Arbeit bzw. zum Weiterarbeiten zu schaffen.
Dies kann auf technischem oder sozialem Weg erreicht werden.
Wir haben uns dafür entschieden, beide Wege zu nutzen, um ein möglichst großes Publikum anzusprechen.
So haben wir technische Anreize beispielsweise über auf der Seite veröffentlichte Bestenlisten realisiert, oder durch einfache,
schön anzuschauende Statistiken der User selbst. Die Realisierung technischer Anreize und Funktionen, die sich für Nutzer belohnend anfühlen,
bietet ein großes Spektrum an Möglichkeiten.
Leider ist gerade dieses Thema jedoch eines, das eher nach Hinten verschoben werden musste,
da es unter Beachtung unseres Zeitrahmens nach der Basisfunktionalität ein zweitrangiges Ziel darstellt.
Deswegen ist an dieser Baustelle auch nur die bisher beschriebene Menge an Funktionen aufgebaut worden.%beschrieben wo genau? FIXME

Wichtig sind jedoch auch die nicht-technischen Anreize.
Diese müssen vielen Nutzern jedoch erst vor Augen geführt werden.
Bedenkt man die Fülle an Datenmaterial, welches wir zur Verfügung stellen, so ist es kaum vorstellbar,
dass ein einziger Nutzer mit vertrebarem Zeitaufwand alle Dokumente transkribieren kann.
Diese Arbeitsleistung wird erst dadurch möglich, dass eine größere Gemeinschaft sich der Aufgabe annimmt.
Im Umkehrschluss bedeutet das aber auch, dass man die Ergebnisse anderer Nutzer sehen und von ihnen lernen könnte.
Jeder, der am Projekt teilnimmt, tut dies mit großer Sicherheit aus dem Grund,
dass er ein gewisses Interesse und Wissen in dem Gebiet hat, und dieses teilen oder vergrößern möchte.
Unsere Plattform bietet diesen zwei Interessentengruppen genau das.
Selbst wenn also ein Nutzer kaum nutzbares Wissen hat, so kann unsere Plattform doch auch für ihn profitabel sein.
Er könnte dadurch mehr lernen, und unter Umständen dieses neu erworbene Wissen im gleichen Atemzug anwenden.
Unsere Nutzergemeinschaft lebt also letzten Endes davon, dass jeder seine eigenen Wissensfetzen mitbringt
und jeder von den anderen lernen kann und somit etwas Gutes für sich und für den wissenschaftlichen Erkenntnisgewinn tut.%etwas Gutes zu subjektiv. FIXME
Wenn wir diese Erkenntnis vermitteln können, dann ist auch damit ein großer Anreiz geschaffen.
Außerdem schaffen wir die Möglichkeit, sich in einer interessenbezogenen Gemeinschaft austauschen zu können.

Bedenken wir die Motivation, die für einen Benutzer geschaffen wird, so ergibt sich auch ein gewisses Bild von der Zielgruppe, die wir anzusprechen versuchen.
Natürlich wird niemand ausgeschlossen, der Interesse an der Arbeit hat und soll mittels Tutorial an die Aufgabe herangeführt werden.
Doch wir erwarten, dass der größte Teil unserer Teilnehmer sich aus einem Publikum zusammensetzt,
das zumindest einen Bezug zur Wissenschaft und der lateinischen Sprache hat.
Das betrifft vorwiegend Geistes- sowie Sprachwissenschaften. Auch geschichtsinteressiertes Publikum wird erwartet,
ebenso wie Teilnehmer, die einfach ein persönliches, nicht-wissenschaftliches Interesse an altertümlicher Sprache besitzen.
Das steckt weitestgehend unsere Erwartungen ab, wobei es durchaus interessant wäre, in einem späteren Stadium einmal eine Umfrage zu starten, um zu sehen,
welchen Bezug die Nutzer zu unserem Projekt haben. Mit diesem Wissen könnten eventuell weitere Anreize eingebracht werden.

%TODO SO FAR
%Rückbezug zur Einordnung unserer Software in die entsprechende Kathegorie von Citizen Science.
%Warum sollen sich Nutzer registrieren?

\section{Produktfunktion}
Dass Nutzer sich planmäßig auf unterschiedlichen Wegen an der Arbeit beteiligen können sollten wurde bereits in unseren Zielen angerissen.
An dieser Stelle sollten wir erwähnen,%ohne sollten FIXME
dass unsere anfänglichen Ziele mit dem aktuellen Arbeitsstand bei weitem nicht übereinstimmen.
Kommt ein Nutzer auf unsere Seite, so wird er von einer Willkommensseite empfangen.
Von dort aus kann er, wie auch von jeder weiteren Seite aus, unsere Oberfläche über Schaltflächen durchblättern.
Diese beinhalten eine ,,About''-Schaltfläche, unter deren Link eine Beschreibung unseres Projektes zu finden sein wird, einen ,,Scans''-Knopf,
unter dem eingeloggte Nutzer die Bibliothek der vorhandenen Scans einsehen und zur bearbeitung voranschreiten können, einen ,,Statistics''-Knopf,
unter dem der Nutzer diverse Statistiken zum Projekt und Community-Fortschritt einsehen können soll,
sowie ein selbsterklärender ,,Contact''-Knopf und ein Drop-Down-Menü namens ,,Transcribing''.
Unter diesem sollen in Zukunft eine Beschreibung von Transkriptionen, ein Screenshot-basiertes Tutorial zum Einstieg in die Arbeit,
eine Übersicht über alle bisher erfolgreich von der Community transkribierten Dokumente, sowie ein Schnellstartknopf zu finden sein.
Der Schnellstartknopf liefert momentan ein fest einprogrammiertes Dokument,
soll später jedoch ein zufälliges Dokument aus einer festgelegten Menge von Scans auswählen und einen direkt in das Transkribtionsfenster bringen.
Die meisten der genannten Links sind nach aktuellem Stand noch leer, mit einem Vermerk,
dass sie sich im Aufbau befinden. Zu guter Letzt findet sich noch ein Login-Knopf in unserer Navigationsleiste.
Durch Betätigung wird der Nutzer angefragt, ob er sich über seinen Facebook-, Github- oder Twitteraccount authentifizieren möchte.%Remove Face,Twt FIXME
Die Authentifikationsroutine haben wir ausgelagert, um uns nur in geringem Maße mit der Verwaltung von Nutzerkonten befassen zu müssen.
Momentan funktioniert allerdings nur die Authentifizierung über den Github-Account.
Nach dem einloggen wird der Nutzer auf seine Profilseite verwiesen, welche im eingeloggten Zustand über einen weiteren Knopf
in der Navigationsleiste ebenfalls erreicht werden kann.

Die bisher als zwei Arbeitsabläufe geplanten Aufgaben,
zum Aufbau einer Interest Map und jene zum eigentlichen Transkribieren sind momentan
aufgrund einer anfänglichen Misskommunikation in einer einzigen Ansicht implementiert.% Not clever to keep. FIXME
Dort lassen sich, momentan auch noch als nicht angemeldeter Nutzer,
Areas of Interest markieren, benennen, und direkt auf der rechten Seite des Bildschirms transkribieren.
Die linke Seite des Bildschirms bietet dem Nutzer den Scan in einer herein- und herauszoombaren Ansicht an, die über die ,,+''- und ,,-''-Schaltflächen,
oder einfach mittels Mausrad verwendet werden kann. Das Dokument kann mittels linker Maustaste bewegt und herumgezerrt werden.
Über die Schaltfläche mit dem Quadrat-ähnlichen Symbol wird der ,,Area of Interest''-Modus aktiviert.
In diesem Modus bewirkt ein linker Mausklick, dass eine Ecke einer Area of Interest festgelegt wird.
Ein zweiter Mausklick an anderer Stelle legt die gegenüberliegende Ecke der Box fest.
So können mehrere Boxen gezogen werden, bis die Schaltfläche erneut betätigt wird.
Alle in der Zwischenzeit festgelegten Boxen sind damit zusammengehörig und können nach dem Tastendruck mit einem Namen versehen und anschließend transkribiert werden.
Über die ,,R''-Schaltfläche lässt sich die zuletzt gezogene Box wieder entfernen.
Diese Funktion ist momentan noch nicht ausgereift, da sie nur die zuletzt gezogene Box entfernt,
nicht aber eine gesamte Area of Interest (welche aus mehreren Boxen bestehen kann).
Eine Möglichkeit, die fertige Arbeit abzuspeichern ist momentan noch nicht implementiert.

Die zwei Routinen zum Interest Map Erstellen und zum Transkribieren sind im Backend bereits getrennt
und müssten dementsprechend nur noch in der Maske getrennt werden, um wie angedacht zu funktionieren.
Das ist bisher alles, was an für den Nutzer sichtbaren, beziehungsweise für den Nutzer interessanten Funktionen implementiert wurde.
Abweichungen von den Zielen sind mitunter durch unerwartete Verzögerungen beim Aufsetzen der von uns verwendeten Technologien begründet.
Durch die zeitliche Begrenzung des Projektes werden entsprechende offene Baustellen von unserer Seite her leider offen bleiben.

%Wie können Nutzer an der Seite teilhaben?
%Wie registrieren sich Nutzer?
%Welche Arbeitsabläufe gibt es?

\section{Architektur}
\subsection{Verwendete Technologien}
In diesem Abschnitt werden die Technologien erläutert,
die zum realisieren der TranscriptionDesk Website genutzt wurden.
Als Grundlage des Entwicklungsprozesses griff die Projektgruppe auf Vagrant\footnote{
    \url{https://www.vagrantup.com/}\\
    \url{https://en.wikipedia.org/wiki/Vagrant_(software)}}
zurück, welches darauf abzielt, eine einheitliche und minimale Entwicklungsumgebung zu schaffen.
Dies wird möglich, indem Vagrant eine virtuelle Maschine provisioniert\footnote{
    Es lässt sich mit Docker auch eine reine Containerlösung nutzen.\\
    \url{https://www.docker.com/}},
die einem genau festgelegten Setupscript, dem Vagrantfile, folgt.
Da dieses Setup unabhängig von der sonstigen Konfiguration der Entwicklermaschine ist,
lassen sich leicht einheitliche Ausgangsbedingungen etablieren.
Zudem ist es später leicht machbar, Vagrant zu benutzen,
um das Projekt auf einem Server einzurichten.
Bei unserem Setup gehen wir von einem Ubuntu Vivid 64bit aus,
das mit systemd\footnote{
    \url{https://wiki.freedesktop.org/www/Software/systemd/}\\
    \url{https://en.wikipedia.org/wiki/Systemd}}
läuft. Systemd ist ein neuerer System- und Servicemanager für Linux,
den wir uns im speziellen zu nutze machen,
um mittels timer in regelmäßigen Zeitabständen
ein PHP script auszuführen,
dass Daten von Omeka zu sammelt.%FIXME Gesamtübersicht vor Technologien, wegen Omeka?

Innerhalb unseres Vagrantsetups betreiben wir einen LAMP-Stack\footnote{\url{https://en.wikipedia.org/wiki/LAMP_(software_bundle)}},
das heißt, dass wir die weit verbreitete Kombination von Linux, Apache2\footnote{
    \url{https://httpd.apache.org/}
    \url{https://en.wikipedia.org/wiki/Apache_HTTP_Server}}, MySQL\footnote{
    \url{https://www.mysql.com/}
    \url{https://en.wikipedia.org/wiki/MySQL}} und PHP\footnote{
    \url{https://secure.php.net/}
    \url{https://en.wikipedia.org/wiki/PHP}} nutzen.

Basierend auf dieser serverseitigen Installation liefern wir eine Website an die Browser der Nutzer aus,
die JavaScript\footnote{
    \cite{Flanagan},
    \url{https://en.wikipedia.org/wiki/JavaScript}} enthält, dass es uns ermöglicht,
erweiterte Funktionalitäten im Browser bereit zu stellen,
und so komplexere Aufgaben wie das Markieren von Areas of Interest
in einer Angenehmen Oberflächte zu präsentieren.
Dabei greifen wir auf unterschiedliche JavaScript Bibliotheken zurück:

\begin{description}
\item[jQuery:]
    Bei jQuery\footnote{\url{https://jquery.com/}} handelt es sich um eine beliebte JavaScript Bibliothek,
    die die Manipulation und das Durchsuchen des DOM\footnote{\url{https://en.wikipedia.org/wiki/Document_Object_Model}} sowie
    den Umgang mit Events und Ajax\footnote{\url{https://en.wikipedia.org/wiki/Ajax_(programming)}} requests vereinfachen soll.
\item[ace:]
    DESCRIBE ME!
\item[openLayers:]
    DESCRIBE ME!
\item[jquery-ui:]
    %Where exactly do we use this? % FIXME
    DESCRIBE ME!
\item[bootstrap:]
    DESCRIBE ME!
\item[bootbox:]
    DESCRIBE ME!
\item[Require.js:]
    DESCRIBE ME!
\end{description}

\subsection{Gesamtübersicht}
Wir wollen diesen Abschnitt nutzen, um ein Bild darüber zu geben,
wie die einzelnen Komponenten der TranscriptionDesk Software zusammen arbeiten.
In Abbildung \ref{fig:components} haben wir dafür die minimal notwendigen Systeme,
den TranscriptionDesk Server, den Omeka Server Homer, und einen Client Browser, abgebildet,
und mittels Pfeilen markiert, zu welche Komponenten mit welchem System in Verbindung stehen.
\\\begin{figure}[H]
\includegraphics[width=\textwidth]{../notes/components.pdf}
\caption{Diagramm einzelner Komponenten der TranscriptionDesk Website}
\label{fig:components}
\end{figure}

Auf dem Server Homer ist eine Instanz der Omeka\footnote{\url{http://omeka.org/}} software installiert.
Innerhalb dieser Instanz werden die Scans verwaltet, und anderen Teilnehmern im Internet bereit gestellt.
Um Informationen über einzelne Scans,
deren Metadaten, und Sammlungen von Scans verfügbar zu machen,
stellt Omeka eine eigene API bereit,
von der wir mittels der PHP Omeka komponente in regelmäßigen Zeitabständen Daten sammeln.

Die auf der TranscriptionDesk-Installation laufende MySQL Datenbank dient als Speicherplatz für alle anfallenden Informationen,
sie wird gegenüber dem Rest der Website durch die PHP DB Logic Komponente gekapselt,
die aus einer Reihe von Klassen besteht, deren Aufgabe es ist,
Teile der domänenspezifischen Logik und Queries an die Datenbank zusammenzufassen
und für den Rest des PHP codes verwendbar zu machen.

Aufgabe der PHP Website Logic ist es,
aus den vorliegenden Informationen ein Website zusammen zu setzen,
und den zu verwendenden JavaScript code sowie von uns genutzte Teile des Bootstrap frameworks in die Website einzubetten.
Bootstrap und JavaScript sind hier als getrennte Komponenten dargestellt,
da sie sich prinzipiell auch auf andere Server verschieben lassen.

Zum Anzeigen von Scans auf dem Clientgerät baut der Client neben der Verbindung zum TranscriptionDesk Server auch eine Verbindung zu Omeka auf Homer auf,
um die anzuzeigenden Scans zu erhalten.

\subsection{Datenbank}
In diesem Abschnitt widmen wir uns dem Aufbau der Datenbank.
Da wir mit MySQL eine relationale Datenbank einsetzen,
werden anfallende Daten auf einzelne Tabellen verteilt gespeichert,
die zueinander in Relation stehen.

\begin{figure}[H]
\includegraphics[width=\textwidth]{../notes/ER.pdf}
\caption{Entity-Relationship Diagramm der Datenbank}
\label{fig:er}
\end{figure}

Wie dem Entity-Relationship Diagramm in Abbildung \ref{fig:er} entnommen werden kann,
gibt es in unserer Datenbank 5 Grundlegende Tabellen,
und 4 weitere Tabellen,
die $n:m$ Relationen zwischen diesen realisieren.

\begin{description}
\item[omekaItems:]
    Die Tabelle omekaItems wird von einem systemd timer,
    der die Omekainstanz auf Homer crawled,
    regelmäßig mit Daten befüllt.
    Um eindeutig feststellen zu können,
    welche Datensätze geändert und welche hinzugefügt werden müssen,
    speichern wir dafür sowohl die URL,
    als auch die zugehörige URN jedes Items.
    Um Aufschluss darüber zu haben,
    ob und welchen Besuchern wir bestimmte Datensätze anzeigen dürfen,
    hat jeder Datensatz Booleans in den Feldern public und featured.
    Die von diesen Feldern abgeleitete Zugriffslogik sieht wie folgt aus:

    \begin{tabular}{r|l}
    Nutzer & Bedingung\\\hline
    Unregistrierter Besucher & $\texttt{public}\land\texttt{featured}$\\
    Registrierter Benutzer & $\texttt{featured}$
    \end{tabular}

    Weiterhin gibt es noch das Feld dublinCoreJSON,
    in dem die Dublin Core Daten aus Omeka im JSON Format abgelegt werden.
    Diese Abweichung vom relationalen Paradigma bei Datenbanken wählten wir,
    da die Dublin Core Daten sich teilweise stark unterscheiden,
    und keiner gezielten Selektion durch SQL bedürfen.
\item[scans:]
    In der Tabelle scans sammeln wir die Daten zu allen einzelnen Scans,
    wie wir sie mittels des systemd timers erhalten.
    Genau wie die omekaItems Tabelle hat auch die scans Tabelle Felder für URN und URL.
    Zusätzlich gibt es das Feld scanDataJSON,
    in dem Metadaten zum Scan gesammelt werden.
    Dazu zählen etwa die unterschiedlichen Auflösungen,
    in denen ein Scan verfügbar ist,
    oder das Dateiformat des Scans.
\item[areasOfInterest:]
    Alle von Nutzern der TranscriptionDesk Website markierten Areas of Interest werden in der areasOfInterest Tabelle gespeichert.
    Für jede Area of Interest wird eine eindeutige URN generiert,
    und der Zeitstempel ihrer Erstellung gespeichert.
    Da Areas of Interest einen Typ und in manchen Fällen auch eine Beschreibung haben sollen,
    gibt es in dieser Tabelle die Felder typeEnum und typeText.
\item[transcriptions:]
    Die transcriptions Tabelle ordnet jeder Area of Interest eine Transcription im Markdown format zu,
    sowie den Zeitstempel des speicherns und eine eindeutige URN, die von der der zugehörigen Area of Interest abgeleitet wird.
\item[users:]
    Um Nutzern die Registerierung zu ermöglichen,
    sowie eine einfache Rechteverwaltung zu etablieren,
    gibt es die Tabelle users.
    Jeder Eintrag dieser Tabelle verfügt über eine eindeutige Nummer, die userId.
    Im Feld authenticationMethod speichern wir JSON encodiert Daten,
    die den Authentikationsservice beschreiben,
    und eine eindeutige Zuordnung eines Nutzers zu einem Authentisierungsservice wie z.B. GitHub ermöglichen.
    Um Nutzern einen grundlegenden Grad von Anonymität zu ermöglichen,
    gibt es das Feld displayName,
    in dem der Name des Nutzers eingetragen ist,
    der auf der Seite angezeigt werden soll.
    Wir speichern außerdem im Feld tasksCompleted
    die Anzahl der Aufgaben, die ein Nutzer erledigt hat,
    d.h. die Summe aller erstellten Areas of Interest, Transkriptionen,
    und teilgenommener Abstimmungen.
    Um feststellen zu können, welche Area of Interest oder welche Transkription
    von welchem Nutzer erstellt wurden,
    haben die jeweiligen Tabellen Felder,
    die auf einen Eintrag in der users Tabelle verweisen.
\end{description}

Neben diesen grundlegenden Tabellen sind 3 weitere Tabellen hervorzuheben:
Die Tabellen aoiCompleteness, scanCompleteness und transcriptionCompleteness
realisieren Abstimmungen über die Vollständigkeit der jeweiligen Areas of Interest, Transkriptionen, und scans.
Das bedeutet, dass Nutzer abstimmen können,
für wie gelungen sie eines der jeweiligen Artefakte halten,
und ob sie die Arbeit mit diesem für beendet erklären wollen.
Bei diesen Abstimmungen können Nutzer entweder zustimmen oder ablehnen.
In der Software lässt sich eine Anzahl Stimmen konfigurieren,
die für Zustimmung oder Ablehnung notwendig ist,
und als Entscheidung der Nutzerbasis gewertet wird.
Stimmt ein als Administrator markierter Nutzer ab,
so wird dessen Stimme sofort als Entscheidung gewertet.

\section{Projektverlauf}
In diesem Abschnitt möchten wir den Ablauf unseres Projektes
von den ersten Treffen bis hin zum finalen Stand berichten.
Dass nicht immer alles planmäßig verläuft liegt in der Natur der Sache.
Deswegen möchten wir die unterwegs aufgetretenen Probleme genauer betrachten,
und unsere Entscheidungen und Abwägungen nachvollziehbar darlegen. \\
Ausgehend von unseren bereits erwähnten Zielen waren wir zu Beginn in der Lage,
notwendige Technologien abzuschätzen.
Dabei legten wir viel Wert auf die Auslagerung von Funktionen auf Dienste,
welche die benötigte Funktionalität bereits implementiert haben
und zur Verfügung stellen und stellten fest,
welche Frameworks und Sprachen wir benötigen würden.
Danach legten wir die groben Entwicklungsetappen fest,
welche bereits in Form unserer drei Meilensteine unter Punkt 3.1. Erwähnung fanden.
Die Meilensteine hatten allerdings nicht von Anfang an diese Form.
Nur den ersten Meilenstein konnten wir zu diesem Zeitpunkt bereits klar abgrenzen.
Uns war klar, dass auch mindestens ein zweiter Meilenstein von Nöten wäre.
Dieser hatte zu diesem Zeitpunkt allerdings kaum konkrete Ziele,
und die Entstehung eines dritten Meilensteines war zu
diesem Zeitpunkt weder angedacht noch ausgeschlossen worden.
Zwischenzeitlich wurde sogar ein vierter Meilenstein geplant,
doch unser erster Meilenstein erfüllte letzten Endes mehr Anforderungen als geplant,
so dass sich die Planung nach hinten wieder anders gestaltete.
Wir wussten zu Beginn,
dass die Scans auf einem Fileserver liegen,
was aus rechtlichen Gründen aber nicht so bleiben sollte.
An diesem Punkt gab es noch keine konkrete Antwort auf die Frage,
von wo wir die Bilder beziehen,
und wie wir entsprechend darauf zugreifen könnten.
Außerdem waren wir uns schon einig, dass wir,
in Anlehnung an das Homer-Multitext-Projekt,
ebenfalls Areas of Interest verwenden möchten,
welche im dortigen Projekt als ,,Regions of Interest'' bezeichnet werden.
Wir waren uns auch einig,
dass Rechtecke die optimale Form wären,
um diese Regionen zu markieren,
wussten nur noch nicht mit Sicherheit,
in welcher Form wir diese Umsetzen und abspeichern sollten.
Unser Favorit war die Variante,
dass Rechtecke nur parallel zu den Seiten verlaufen könnten und man lediglich zwei Punkte,
oder einen Punkt sowie Höhe und Breite abspeichern müsste.
Nach kurzer Bedenkzeit entschieden wir uns für die zuletzt genannte Variante.
Außerdem waren wir schon zu Beginn darüber im Bilde,
dass Nutzer sich in irgendeiner Form Registrieren können sollten,
und dass dies eine Voraussetzung wäre,
um auf die Daten zugreifen zu können.
Deswegen war die Login-Routine eine der ersten beschlossenen Funktionen.
Außerdem war ebenfalls klar,
dass Arbeit nur im eingeloggten Zustand verrichtet werden darf. \\
Eine Woche später kam Omeka als Server für unsere Bilddateien ins Gespräch.
Dort sollten wir einen Contributor-Nutzerzugang bekommen,
um über diesen Zugang zu den Scans zu erhalten.
Schnell stellte sich auch die Frage,
ob wir ein Omeka-Plugin bauen müssten,
oder ob es hierfür bereits implementierte Instrumente gäbe,
deren Verwendung für uns in Frage kommt.
Noch am selben Tag entschlossen wir uns dazu,
für die Anmeldung einen Authentication Provider zu verwenden. \\
Am 19. Juni gab es das nächste Zusammenkommen.
Dort diskutierten wir,
welche Informationen wir von Omeka beziehen müssten.
Unsere Antwort darauf bestand aus Items sowie Metadaten.
Dazu gehören unter anderem auch Copyrights und die Sammlungen,
zu denen die jeweiligen Scans gehören. Wir entschieden uns,
mit den Tags ,,Public'' und ,,Featured'' so zu verfahren,
das erstere auch nicht eingeloggten Nutzern auf unserer Plattform angezeigt werden dürften,
während Featured Scans lediglich für eingeloggte Nutzer angezeigt werden dürften.
Scans, die weder Featured noch Public Tags aufweisen,
würden wir behandeln, als existierten sie nicht,
und sie entsprechend auch keinem Nutzer anzeigen.
Für unsere Datenbank entschieden wir,
dass alles mögliche einen Zeitstempel aufweisen dürfte,
und es demnach auch tun sollte. Außerdem entschieden wir,
dass wir unsere um die Area of Interest erweiterten
Cite URNs zusätzlich hinten um den Nutzernamen,
einen Zeitstempel, sowie die Endung ,,.md'' erweitern wollen.
Zu diesem Zeitpunkt legten wir unseren ersten Meilenstein auf
Github an und hakten bereits die Issues der ersten Phase als erledigt ab.
Dazu gehörten die Mockups der Datenbank,
des Interfaces sowie des Omeka Service Providers.
Auch der Registrationsprozess gehörte dazu,
während wir hier noch überlegten,
wie wir vermeiden könnten,
Passwörter auf unserer eigenen Datenbank abspeichern zu müssen. \\
Am 24. Juni war der Stand unserer Arbeit so,
dass wir bereits Scans aus Omeka lesen und diese,
sowie entsprechende Thumbnails,
anzeigen konnten.
Am selben Tag begannen wir damit,
das bereits vorgestellte ER-Diagramm für die Datenbank anzulegen.
Wir klärten auch ab,
dass Nutzer die Möglichkeit haben sollten,
die Interest Maps anderer Nutzer editieren zu können.
Das editierte Ergebnis sollte als neue Interest Map abgespeichert werden,
anstatt das Original zu überschreiben.
Eine Frage,
zu diesem Datum ungeklärte Frage befasste sich damit,
ob wir eine Referenzkette bilden sollten,
welche es möglich macht,
die Bearbeitungsgeschichte zurück zu verfolgen. \\
Schon am 26. Juni gab es ein nächstes Treffen.
Um uns allen ein laufendes Setup einzurichten,
versuchten wir,
Docker unter Windows bei Oliver einzurichten.
Dazu gibt es Boot2Docker,
welches explizit unter Windows funktionieren soll,
jedoch funktionierte dieser Ansatz nicht,
da das Setup möglicherweise kaputt war - so unser Verständnis davon.
Man hätte auch in der laufenden Arbeit weitere Probleme erwarten müssen,
weswegen wir den Kurs änderten und versuchten,
ein Ubuntu in einer VirtualBox einzurichten,
damit wir eine Ausweichmöglichkeit hätten.
Das Setup nahm jedoch einige Zeit in Anspruch und wurde nicht mehr am selben Tag fertig.
Zeitgleich arbeitete sich Robert weiter in Bootstrap und PHP
ein und es entstand in weiteren Überlegungen ein Tafelbild,
welches als Grundlage für die oben gezeigte Komponentengrafik fungierte,
welche wir mit Yed erstellten. \\
Am 1. Juli kamen wir wieder zusammen.
Im gespräch mit Thomas wurden wir für unser Setupproblem auf Vagrant aufmerksam
gemacht und setzten uns auch direkt an die Umsetzung dieses Lösungsansatzes.
Vor allem sollte es unter Windows besser laufen.
Jakob war von Vagrant nicht hundertprozentig überzeugt und überlegte,
inwiefern wir uns noch Docker zunutze machen könnten,
wir wurden jedoch gebeten,
Vagrant eine Chance zu geben und haben es entsprechend umgesetzt.
Die Überlegung,
Docker weiterhin zur Provisionierung einzusetzen,
war trotzdem da.
Zudem kam ins Gespräch,
dass es von Vorteil wäre,
Markdown auf Github speichern zu können.
In diesem Zuge wurde uns auch gesagt,
dass wir die MUFI-Symbole nicht pur benutzen sollten,
sondern nur jene,
die auch in UTF-8 enthalten seien.
Zuletzt beschäftigten wir uns mit unseren Bilddateien.
Wir wurden darüber informiert,
dass ein Bilderproxy nicht teil unseres Systems sein muss.
Uns wurden zwei Werkzeuge vorgeschlagen,
welche Funktionalitäten besitzen,
die wir möglicherweise gut für all das gebrauchen könnten,
was wir auf unserem System mit Bilddateien machen können müssen.
Namentlich sind das ,,OpenSeadragon'' und ,,iiif''. \\
Bei unserem Treffen am 3. Juli schafften wir es,
Vagrant bei Oliver zum laufen zu bringen und so
ein funktionierendes Setup unter Windows aufzubauen.
Wir hatten unsere Zweifel,
jedoch wäre es ohne Vagrant noch viel komplizierter gewesen.
Die Sorge,
dass Vagrant an anderen Stellen noch Probleme machen könnte,
bleibt jedoch.
Robert hat am selben Tag ein Mockup fertiggestellt,
in welchem Zooming und Panning möglich sind und eine Drawbox zu sehen ist.
Danach widmeten wir uns wieder unterschiedlichen, kleinen,
technischen Aufgaben und Bugs, während Oliver versuchte,
die aus dem Mockup ersichtlich werdenden Anforderungen
einmal in einem kleinen Dokument zu erfassen.
Da das Mockup das an diesem Tag entstand dieselbe Version ist,
die auch momentan noch in unserem Code zu finden ist,
in der das Markieren von Areas of Interests und das
Füllen derer Informationsboxen im gleichen Prozess geschieht,
ging es in dem Dokument weitestgehend um Ideen zur
Trennung dieser zwei Mechhanismen in eigenständige Aufgaben. \\
Am 8. Juli beschlossen wir,
Transkriptionen bei Konsens auf Github zu stellen.
Die URNs sollten dabei als Dateinamen dienen.
Beteiligte Nutzer sollen im Commit erwähnt werden.
Das betrifft all jene,
welche die Transkription erstellt,
oder sie abgesegnet haben.
Thomas Gedanke dazu ist,
dass es zur Absicherung einer fertigen Transkription reicht,
wenn fünf Nutzer meinen,
alles wäre korrekt,
oder wenn dies von einem Admin bestätigt wird.
Für uns ergibt sich daraus die Anforderung,
einen isAdmin-Flag in die Nutzerbasis einzubauen.
Es gab auch Überlegungen zum Motivationssystem,
wodurch ins Gespräch kam,
dass Nutzer mit einer gewissen Anzahl an fertiggestellten
Tasks ebenfalls wie Administratoren gewertet werden könnten.
Auch CTS URNs wurden uns für unsere Scans zugänglich gemacht.
Wir überlegten,
wie wir uns diese in Omeka zunutze machen könnten
und dachten dabei an Dublin Core und Google Fusion.
Zusätzlich kam die Idee auf,
die Dateinamen zu diesen URNs hinzuzufügen,
um die Erkennung unserer Inhalte zu erleichtern.
Dann besprachen wir Baustellen für unseren nächsten Meilenstein,
konnten zu diesem Zeitpunkt jedoch nur das abspeichern von Areas of Interests,
sowie ein Bewertungssystem von Interest Maps und eine Eingabemaske für MUFI-Symbole festmachen.
Noch wussten wir auch nicht,
wie wir den Nutzern Scans anbieten sollten.
Die erste Idee war es,
sowohl eine Möglichkeit zur gezielten suche nach Scans einzubauen,
sowie auch eine Möglichkeit,
einen zufälligen Scan zur Arbeit gegeben zu bekommen. \\
Am 10. Juli haben wir viele Entscheidungen zusammen mit Thomas und Christine getroffen.
Zuerst kam der Vorschlag,
mehrere Kategorien für unsere Areas of Interest zu machen.
Folgende Kategorien sind daraufhin Fazit entstanden:
,,Main Text'', ,,Marginal Text'', ,,Image'', ,,Mathematical Figure'',
,,Other (Freetext description)'', ,,Initials'' und ,,Title''.
Auch wurde zu bedenken gegeben,
dass es Sätze geben kann,
die sich über mehrere Scans überspannen.
Daher sollte es möglich gemacht werden,
Areas of Interest über mehrere Scans hinweg zu markieren,
und ein entsprechendes Feature zu implementieren,
welches das Blättern ermöglicht.
Wir dachten uns dazu,
dass es ausreichen müsste, vom Scan, um den es geht,
jeweils nur eine Seite vorwärts oder rückwärts blättern zu können.
Außerdem stellten wir fest,
dass eine Fehlerbehandlung nötig werden könnte,
falls URNs eine länge von 250 Zeichen überschreiten.
Deswegen müssen wir dies immer dann überprüfen,
wenn eine URN erstellt oder verändert wird.
Wir haben auch darn übereingestimmt,
dass im Tutorial darauf hingewiesen werden sollte,
dass Areas of Interest so sparsam wie möglich eingesetzt werden,
und nur so viele gezogen werden,
wie unbedingt nötig ist.
Am Ende der Sitzung erstellten wir noch Schemata für unsere URNs.
Weiterhin möchten wir unter anderem Metadaten aus
Dublin Core in unsere Transkriptionsansicht übernehmen.
Außerdem beschlossen wir,
dass es in Ordnung wäre,
unsere Authentifikation für den moment auf Github zu beschränken.
Möglicherweise wird es im Rahmen unseres Projektes auch dabei bleiben.
Weiterhin wäre es gut,
ein MUFI-Keyboard direkt unter der Markdowneingabe einzusetzen.
Es könnte außerdem ein Live-Rendering von Markdown möglich gemacht werden,
sofern wir dies in einem eigenen Tab innerhalb unserer Seite realisieren können.
Es wurde beschlossen für die Größe der Rechtecke mit Percentages und Doubles zu arbeiten,
da diese im Gegensatz zu Pixelzahlen mit der Bildgröße skaliert werden können.
Und wir haben festgelegt,
dass immer wenn ein Nutzer Markdown auf Github exportiert,
soll darauf ein automatisch generiertes Preface existieren,
welches einen Link auf das Profil des Autoren,
inklusive Nutzernamen,
einen Link auf die Transkription über ihre URN,
sowie weitere Daten zur Transkription enthält.
Außerdem ist erwähnenswert,
dass auch Robert seit unserem Wechsel zu Vagrant an
diesem Tag wieder ein Setup zum laufen bekommen hat.
Der Stand unseres Projektes an diesem Tag hat damit
den Bestand für unseren ersten Meilenstein erfüllt. \\
Unser vorerst letztes geregeltes Treffen fand am
15. Juli mit dem Ende der Vorlesungszeit statt.
Wir besprachen an diesem Datum nicht viel,
nennenswert ist nur,
dass wir testen müssten,
ob es ausreichen würde,
TIFF-Dateien im Browser anzuzeigen,
oder wir diese in ein anderes Datenformat konvertieren müssten. \\
Eine Sache,
die später noch zu Problemen führte,
war die Gestaltung des MUFI-Keyboards.
Es gab an einem Punkt eine Eingabemaske,
welche sich an MUFIs Kategorisierung der Symbole orientierte.
Da MUFI jedoch eine gewaltige Symbolauswahl hat und sich dessen Kategorien an
keiner praktischen Form für die Auswahl von Symbolen im Schriftfluss orientiert,
war diese variante sehr ungeeignet.
Eine bessere Organisierung wurde notwendig,
doch ein Wechsel der Technik war schwierig zu planen.
Unsere neue Lösung bestand darin,
die von MUFI vorgegebenen Kategorien aufzubrechen
und eine neue Kategorisierung zu schaffen,
die sich eher an Symbolähnlichkeit und Eingabefreundlichkeit orientierte.
Dazu nutzten wir die einzelnen Wörter in den
Beschreibungsfeldern der einzelnen Zeichen als Tags.
Diese wurden dann mittels Bucket-Sort organisiert
und somit entstand die neue Kategorieform,
welche sich als viel Nutzerfreundlicher erwies. \\
%***An diesem Punkt hören die Notes von Jakob auf.
%Ich weiß nicht, was seither alles passiert ist.
%Ich erinnere mich noch an weitere Vagrant-Probleme?
%Hier muss eventuell noch mit eurer Hilfe nachgebessert werden***
*** The End? ***

\subsection{Aktueller Stand des Projektes}

\section{Zusammenfassung und Ausblick}

\section*{Quellen}
  \printbibliography[%
    heading=bibintoc, % (bibintoc, bibnumbered)
  ]
\end{document}
